{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import yfinance as yf\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all the SP500 & financial indicator ticker symbols through Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sp500 stocks \n",
    "all_tickers_xpath = \"//span[text() = \\\"S&P 500 component stocks\\\"]/following::tbody[1]/tr/td[1]/a\"\n",
    "soup = BeautifulSoup(requests.get(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\").content, 'html.parser')\n",
    "dom = etree.HTML(str(soup))\n",
    "\n",
    "# find all tickers\n",
    "all_tickers = [i.text for i in dom.xpath(all_tickers_xpath)]\n",
    "\n",
    "# look at the first 5 ticker symbols\n",
    "print(\"The first 5 ticker symbols:\")\n",
    "print(all_tickers[:5])\n",
    "\n",
    "# also gather all financial indicator symbols\n",
    "\n",
    "\"\"\"\n",
    "    Here are some of the useful Market indices to track:\n",
    "    \n",
    "    Gold futures and spot prices are a great way to see how the dollar is \n",
    "    changing over a certain period of time, which is reflective of inflation \n",
    "    and market sentiment through futures.\n",
    "\n",
    "    Crude oil prices influence the cost of production and manufacturing across\n",
    "    the country. Reduction of oil prices directly affect the consumer at a large\n",
    "    scale, as there is a greater discretionary income available, serving as a\n",
    "    stimulant for the economy.\n",
    "\n",
    "    The SP500 index tracks the general trend of the SP500 market. This index\n",
    "    value is very helpful when trying to predict price movements because it\n",
    "    is like an estimate of overall market trends.\n",
    "\n",
    "    Market Volatility Index reflects a volatility measure for the next 30 days.\n",
    "    \"VIX values >= 30 are linked to volatility from uncertainty, risk, and\n",
    "    investors' fear. VIX values below 20 correspond to stable, stress-free\n",
    "    period in the markets.\"\n",
    "\n",
    "    US Dollar Index measures the value of the US dollar in relation to a\n",
    "    collection of foreign currencies. The base value of this index is 100\n",
    "    and values are interpreted relative to that base. (we can standardize)\n",
    "        if the index is above 100, the dollar is stronger compared to the\n",
    "        other currencies. otherwise the opposite reflects inverse relation-\n",
    "        ship.\n",
    "\n",
    "    Copper is used across technology, energy, and construction. These prices\n",
    "    will capture a baseline econoimc condition, where rising copper prices\n",
    "    may indicate inflation or tightening economic conditions.\n",
    "\"\"\"\n",
    "\n",
    "# Gold Futures\n",
    "all_tickers.append(\"GC=F\")\n",
    "\n",
    "# Gold Spot Prices (SPDR GLD tracks the price of the gold bullion OTC market)\n",
    "all_tickers.append(\"GLD\")\n",
    "\n",
    "# Crude Oil Futures\n",
    "all_tickers.append(\"CL=F\")\n",
    "\n",
    "# SP500 index (relevant to the entire sector)\n",
    "all_tickers.append(\"^GSPC\")\n",
    "\n",
    "# Market Volatility Index\n",
    "all_tickers.append(\"^VIX\")\n",
    "\n",
    "# US dollar index\n",
    "all_tickers.append(\"DX-Y.NYB\")\n",
    "\n",
    "# Copper futures\n",
    "all_tickers.append(\"HG=F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all stock market data for every ticker symbol on the SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yfinance is very convenient and allows us to do this in one function call\n",
    "tickers_df = yf.download(' '.join(all_tickers), group_by='tickers')\n",
    "tickers_df.to_csv('stock_ticker_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some summary statistics for the ticker data\n",
    "rows_cnt, col_cnt = np.shape(tickers_df)\n",
    "print('Number of rows:', rows_cnt, 'Number of cols:', col_cnt)\n",
    "\n",
    "# see the last bit of data for the group ticker symbols\n",
    "tickers_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Congressional trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 17,000 + 8,000 congressional trading data (pretty useful for all raw data from House)\n",
    "# we have to transform this data into something useful, will research into that later\n",
    "# https://house-stock-watcher-data.s3-us-west-2.amazonaws.com/data/all_transactions.json\n",
    "# https://senate-stock-watcher-data.s3-us-west-2.amazonaws.com/aggregate/all_transactions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_trade_data = requests.get(\"https://house-stock-watcher-data.s3-us-west-2.amazonaws.com/data/all_transactions.json\")\n",
    "senate_trade_data = requests.get(\"https://senate-stock-watcher-data.s3-us-west-2.amazonaws.com/aggregate/all_transactions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the useful information from congressional trading data\n",
    "house_json, senate_json = house_trade_data.json(), senate_trade_data.json()\n",
    "house_df, senate_df = pd.DataFrame(house_json), pd.DataFrame(senate_json)\n",
    "\n",
    "house_df = house_df[['ticker', 'type', 'amount', 'disclosure_date', 'representative', 'sector', 'party']]\n",
    "senate_df = senate_df[['ticker', 'type', 'amount', 'disclosure_date', 'senator', 'sector', 'party']]\n",
    "\n",
    "colnames = ['ticker', 'type', 'amount', 'disclosure_date', 'person', 'sector', 'party']\n",
    "house_df.columns = colnames\n",
    "senate_df.columns = colnames\n",
    "\n",
    "congressional_df = pd.concat([house_df, senate_df])\n",
    "congressional_df.to_csv('congressional_data.csv')\n",
    "\n",
    "del house_json, senate_json, house_df, senate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering all required textual data (for sentiment/ market condition embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am working on 5 years of data for all the tickers given by the SP500.\n",
    "\n",
    "# literally all reddit data held in the Pushshift api dumps for years up to 2023:\n",
    "#   you will need Torrent to deal with this data (ill run it on my computer and push data to github)\n",
    "# https://www.reddit.com/r/pushshift/comments/1akrhg3/separate_dump_files_for_the_top_40k_subreddits/\n",
    "\n",
    "'''\n",
    "    We are pulling from these subreddit sources:\n",
    "        subreddits23/wallstreetbets_submissions.zst\t474.51MB\n",
    "        subreddits23/stocks_submissions.zst\t87.74MB\n",
    "        (these are compressed zstandard file formats)\n",
    "\n",
    "    the source of data:\n",
    "    https://academictorrents.com/details/56aa49f9653ba545f48df2e33679f014d2829c10\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    The file is not going to be present here in this repo (since it is very large), but\n",
    "    the second best way of gathering data would be to specify the filepath for wherever\n",
    "    it is on your system (for me, its on an external SSD).\n",
    "\n",
    "    uncompressed:\n",
    "    r/stocks_submissions is ~800kB\n",
    "    r/wallstreetbets_submissions is ~6Mb\n",
    "\n",
    "    most of that data involve posts with URL/ links or images, which isn't that useful\n",
    "    so there will be a simple heuristic to filter good vs. bad posts.\n",
    "    \n",
    "    because it is impractial to load all of this into memory at once, we will read\n",
    "    the file one line at a time and filter for the desired data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_post(post_json: dict, from_date: datetime.datetime, min_selftext: int = 10,\n",
    "              max_selftext: int = 200, min_score: int = 10, min_num_comments: int = 5) -> bool:\n",
    "    \"\"\"\n",
    "        A heuristic applied to determine whether a post is high quality\n",
    "        or not.\n",
    "    \"\"\"\n",
    "    if not post_json[\"created_utc\"] or type(post_json[\"created_utc\"]) != int:\n",
    "        if type(post_json[\"created_utc\"]) == str and post_json[\"created_utc\"].isnumeric():\n",
    "            post_json[\"created_utc\"] = int(post_json[\"created_utc\"])\n",
    "        elif type(post_json[\"created_utc\"]) == float:\n",
    "            post_json[\"created_utc\"] = int(post_json[\"created_utc\"])\n",
    "        else:\n",
    "            print(type(post_json[\"created_utc\"]), post_json[\"created_utc\"])\n",
    "            raise Exception(\"cannot parse created_utc\")\n",
    "    \n",
    "    post_datetime = datetime.datetime.fromtimestamp(post_json[\"created_utc\"])\n",
    "\n",
    "    if post_datetime < from_date:\n",
    "        return False\n",
    "    \n",
    "    good_post = min_selftext <= len(post_json[\"selftext\"]) <= max_selftext and \\\n",
    "        post_json[\"score\"] >= min_score and post_json[\"num_comments\"] >= min_num_comments\n",
    "    \n",
    "    return good_post\n",
    "\n",
    "def get_reddit_data(filepath: str, from_date: datetime.datetime, min_selftext: int = 10, \n",
    "                    max_selftext: int = 200, min_score: int = 10, min_num_comments: int = 5, \n",
    "                    verbose: bool = True, verbose_increment: int = 100_000) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "        Scans through the PushShift API dumps file and extracts only the relevant post data\n",
    "        for our purposes.\n",
    "    \"\"\"\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Getting reddit data for\", filepath)\n",
    "\n",
    "    relevant_attributes = set([\n",
    "        \"title\",\n",
    "        \"selftext\",\n",
    "        \"num_comments\",\n",
    "        \"score\",\n",
    "        \"created_utc\"\n",
    "    ])\n",
    "\n",
    "    saved_posts = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for lines_processed, line in enumerate(f, start=1):\n",
    "            post_json = json.loads(line)\n",
    "\n",
    "            if good_post(post_json, from_date, min_selftext, max_selftext, min_score, \n",
    "                         min_num_comments):\n",
    "                saved_posts.append({key: post_json.get(key) for key in post_json.keys() if \\\n",
    "                                    key in relevant_attributes})\n",
    "\n",
    "            if verbose and lines_processed % verbose_increment == 0:\n",
    "                print(f\"Processed {lines_processed} lines, len(saved_posts) = {len(saved_posts)}\")\n",
    "    \n",
    "    df = pd.DataFrame(saved_posts)\n",
    "    df[\"created_utc\"] = pd.to_datetime(df[\"created_utc\"], unit=\"s\").dt.date\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_dir = \"D:/Projects/Stock-Predictions/reddit/subreddits23/stocks_submissions\"\n",
    "wsb_dir = \"D:/Projects/Stock-Predictions/reddit/subreddits23/wallstreetbets_submissions\"\n",
    "assert os.path.isdir(stocks_dir)\n",
    "assert os.path.isdir(wsb_dir)\n",
    "\n",
    "stocks_filepath = os.path.join(stocks_dir, stocks_dir.split('/')[-1])\n",
    "wsb_filepath = os.path.join(wsb_dir, wsb_dir.split('/')[-1])\n",
    "\n",
    "assert os.path.isfile(stocks_filepath)\n",
    "assert os.path.isfile(wsb_filepath)\n",
    "\n",
    "from_date = datetime.datetime(2015, 1, 1)\n",
    "\n",
    "# I can use a more restrictive measure for wsb data since there are a lot more posts\n",
    "#   on that subreddit\n",
    "stocks_reddit_df = get_reddit_data(stocks_filepath, from_date=from_date, min_num_comments=5, min_score=5, \n",
    "                                   verbose=True)\n",
    "wsb_reddit_df = get_reddit_data(wsb_filepath, from_date=from_date, min_num_comments=10, min_score=20, \n",
    "                                verbose=True, verbose_increment=500_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are a lot of posts we can use\n",
    "sentiment_df = pd.concat([stocks_reddit_df, wsb_reddit_df])\n",
    "\n",
    "# set a limit for the number of posts per day\n",
    "max_posts_limit = 40\n",
    "sentiment_df = sentiment_df.groupby(\"created_utc\").apply(lambda x: x.sample(n=min(len(x), max_posts_limit))).reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of posts: {sentiment_df.shape[0]}\")\n",
    "sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_counts = sentiment_df.groupby(\"created_utc\").size()\n",
    "# some days have 0 data, while others have a ton of data...\n",
    "plt.bar(x=daily_counts.index, height=daily_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, save the file\n",
    "sentiment_df.to_csv(\"sentiment_text.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Define some functions for technical indicators</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# financial indicator functions\n",
    "# note that these are indented to work with ONE key value\n",
    "# ex. ONLY DATES means that we must group by stock ticker\n",
    "# note: TICKERS will not make sense for these functions as keys\n",
    "\n",
    "def check_series_numeric(column) -> bool:\n",
    "    not_numeric = column.apply(pd.to_numeric, errors = 'coerce').isna().all()\n",
    "    # if the data is not numeric, the test failed \n",
    "    return not not_numeric\n",
    "\n",
    "def calculate_sma(column, period = 10):\n",
    "    if not check_series_numeric(column):\n",
    "        return column\n",
    "    sma = column.rolling(period).mean()\n",
    "    return pd.Series(sma, index= column.index, name = 'SMA')\n",
    "\n",
    "def calculate_ema(column, period = 10):\n",
    "    if not check_series_numeric(column):\n",
    "        return column\n",
    "    ema = column.ewm(span = period, min_periods = period - 1).mean()\n",
    "    return pd.Series(ema, index = column.index, name = 'EMA')\n",
    "\n",
    "def calculate_rsi_helper(column, period = 14, use_exponential = False):\n",
    "    if not check_series_numeric(column):\n",
    "        return column \n",
    "\n",
    "    column = column.astype(float)\n",
    "    # find differences in prices\n",
    "    differences = column.diff() \n",
    "\n",
    "    # clip, but center off of zero value\n",
    "    gain = differences.clip(lower = 0.01)\n",
    "    loss = differences.clip(upper = -0.01)\n",
    "\n",
    "    avg_gain = gain.mean()\n",
    "    avg_loss = loss.mean()\n",
    "\n",
    "    if use_exponential:\n",
    "        # get the exponential weighted mean of the very last element in this current rolling window\n",
    "        avg_gain = gain.ewm(span = period, min_periods = period - 1).mean().iloc[-1]\n",
    "        avg_loss = loss.ewm(span = period, min_periods = period - 1).mean().iloc[-1]\n",
    "\n",
    "    RS = avg_gain / avg_loss \n",
    "    RSI = 100 - 100 / (1 - RS)\n",
    "\n",
    "    return RSI\n",
    "\n",
    "'''\n",
    "    let RS = average gain / average loss   \n",
    "    RSI = 100 - 100 / (1 - RS)\n",
    "\n",
    "    some things to look out for: \n",
    "        - using exponential weighted means on the average\n",
    "            gains and losses made the RSI value much more\n",
    "            sensitive and fluctuating more based on price\n",
    "            changes\n",
    "        - using simple averages made the RSI value more \n",
    "            smoothed out\n",
    "\n",
    "    keyword argument options:\n",
    "        - period: type int\n",
    "        - use_exponential: type bool\n",
    "\n",
    "'''\n",
    "def calculate_rsi(column, period, use_exponential):\n",
    "    rsi = column.rolling(14).apply(lambda x: calculate_rsi_helper(x, period=period, use_exponential=use_exponential)).astype(float)\n",
    "    return pd.Series(rsi, index = column.index, name = 'RSI')\n",
    "\n",
    "'''\n",
    "    MACD (moving average convergence/ divergence) shows the relationship\n",
    "    between two exponential moving averages and comparing this to the \n",
    "    9-day EMA line \n",
    "\n",
    "    MACD = 12-period EMA - 26-period EMA \n",
    "    Signal = 9-period EMA - 26-period EMA\n",
    "'''\n",
    "def calculate_macd(column, long_period = 26, short_period = 12, signal_period = 9) -> tuple[object, object]:\n",
    "    if not check_series_numeric(column):\n",
    "        return column \n",
    "    \n",
    "    # Calculate the short and long EMAs\n",
    "    ewm_short = column.ewm(span=short_period, min_periods=short_period-1).mean()\n",
    "    ewm_long = column.ewm(span=long_period, min_periods=long_period-1).mean()\n",
    "\n",
    "    # Calculate MACD line\n",
    "    macd = (ewm_short - ewm_long).astype(float)\n",
    "\n",
    "    # Calculate the Signal line (EMA of MACD)\n",
    "    ewm_signal = macd.ewm(span=signal_period, min_periods=signal_period-1).mean()\n",
    "    signal = ewm_signal.astype(float)\n",
    "\n",
    "    # Return both MACD and Signal as pandas Series\n",
    "    macd = pd.Series(macd, index=column.index, name='MACD')\n",
    "    signal = pd.Series(signal, index=column.index, name='MACD-SIGNAL')\n",
    "\n",
    "    return macd, signal\n",
    "\n",
    "\"\"\"\n",
    "    Calculate the average stock price between 30 and 45 days after the present day.\n",
    "    Expects that data is given in sorted order by date.\n",
    "\n",
    "    - data: pd.DataFrame with stock data indexed by date.\n",
    "    - column_name: str, the column name containing the stock prices.\n",
    "    This returns the average stock price between 30 and 45 days after the present day.\n",
    "\"\"\"\n",
    "def calculate_future_average_stock_price(column):\n",
    "    # Initialize a new series to store the future averages\n",
    "    future_averages = []\n",
    "\n",
    "    # Iterate over the series to calculate the future average for each index\n",
    "    for i in range(len(column)):\n",
    "        # The future range is from i+30 to i+45 (exclusive of 45)\n",
    "        future_values = column.iloc[i+30:i+45]\n",
    "        future_price = future_values.mean() if len(future_values) > 0 else None\n",
    "        percent_change = future_price / column.iloc[i] if future_price is not None else None\n",
    "        future_averages.append(percent_change)\n",
    "    \n",
    "    # Return the result as a new series\n",
    "    return pd.Series(future_averages, index=column.index, name=\"FutureAverage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframe objects here and avoid running all the pipeline above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the dataframe objects\n",
    "if \"tickers_df\" not in dir():\n",
    "    tickers_df = pd.read_csv(\"stock_ticker_data.csv\", header=[0,1])\n",
    "\n",
    "if \"congressional_df\" not in dir():\n",
    "    congressional_df = pd.read_csv(\"congressional_data.csv\")\n",
    "\n",
    "if \"sentiment_df\" not in dir():\n",
    "    sentiment_df = pd.read_csv(\"sentiment_text.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset to predict AAPL (Apple) price movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrow 3064 ncol 26\n",
      "After some cleanup, here is the AAPL technical indicator dataframe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL:Adj Close</th>\n",
       "      <th>AAPL:Volume</th>\n",
       "      <th>MSFT:Adj Close</th>\n",
       "      <th>MSFT:Volume</th>\n",
       "      <th>AMZN:Adj Close</th>\n",
       "      <th>AMZN:Volume</th>\n",
       "      <th>GOOGL:Adj Close</th>\n",
       "      <th>GOOGL:Volume</th>\n",
       "      <th>META:Adj Close</th>\n",
       "      <th>META:Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>CL=F:Adj Close</th>\n",
       "      <th>CL=F:Volume</th>\n",
       "      <th>^GSPC:Adj Close</th>\n",
       "      <th>^GSPC:Volume</th>\n",
       "      <th>^VIX:Adj Close</th>\n",
       "      <th>^VIX:Volume</th>\n",
       "      <th>DX-Y.NYB:Adj Close</th>\n",
       "      <th>DX-Y.NYB:Volume</th>\n",
       "      <th>HG=F:Adj Close</th>\n",
       "      <th>HG=F:Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-12-01</th>\n",
       "      <td>9.532084</td>\n",
       "      <td>461750800.0</td>\n",
       "      <td>20.012495</td>\n",
       "      <td>74123500.0</td>\n",
       "      <td>8.8275</td>\n",
       "      <td>115402000.0</td>\n",
       "      <td>14.087989</td>\n",
       "      <td>150013836.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>86.750000</td>\n",
       "      <td>340736.0</td>\n",
       "      <td>1206.069946</td>\n",
       "      <td>4.548110e+09</td>\n",
       "      <td>21.360001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.709999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.946</td>\n",
       "      <td>1301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-02</th>\n",
       "      <td>9.584808</td>\n",
       "      <td>462837200.0</td>\n",
       "      <td>20.665745</td>\n",
       "      <td>91759200.0</td>\n",
       "      <td>8.8265</td>\n",
       "      <td>110752000.0</td>\n",
       "      <td>14.274464</td>\n",
       "      <td>101814084.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>330642.0</td>\n",
       "      <td>1221.530029</td>\n",
       "      <td>4.970800e+09</td>\n",
       "      <td>19.389999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.977</td>\n",
       "      <td>907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-03</th>\n",
       "      <td>9.563414</td>\n",
       "      <td>342092800.0</td>\n",
       "      <td>20.765650</td>\n",
       "      <td>52622000.0</td>\n",
       "      <td>8.7840</td>\n",
       "      <td>98150000.0</td>\n",
       "      <td>14.303920</td>\n",
       "      <td>105142752.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>89.190002</td>\n",
       "      <td>354635.0</td>\n",
       "      <td>1224.709961</td>\n",
       "      <td>3.735780e+09</td>\n",
       "      <td>18.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.379997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.995</td>\n",
       "      <td>543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-06</th>\n",
       "      <td>9.645058</td>\n",
       "      <td>448481600.0</td>\n",
       "      <td>20.627316</td>\n",
       "      <td>36264200.0</td>\n",
       "      <td>8.9025</td>\n",
       "      <td>113084000.0</td>\n",
       "      <td>14.437722</td>\n",
       "      <td>83668248.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>89.379997</td>\n",
       "      <td>293836.0</td>\n",
       "      <td>1223.119995</td>\n",
       "      <td>3.527370e+09</td>\n",
       "      <td>18.020000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.570000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.004</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-07</th>\n",
       "      <td>9.586614</td>\n",
       "      <td>391454000.0</td>\n",
       "      <td>20.650375</td>\n",
       "      <td>57860500.0</td>\n",
       "      <td>8.8385</td>\n",
       "      <td>101542000.0</td>\n",
       "      <td>14.656900</td>\n",
       "      <td>121566312.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>88.690002</td>\n",
       "      <td>462689.0</td>\n",
       "      <td>1223.750000</td>\n",
       "      <td>6.970630e+09</td>\n",
       "      <td>17.990000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.860001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.044</td>\n",
       "      <td>1155.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL:Adj Close  AAPL:Volume  MSFT:Adj Close  MSFT:Volume  \\\n",
       "Date                                                                   \n",
       "2010-12-01        9.532084  461750800.0       20.012495   74123500.0   \n",
       "2010-12-02        9.584808  462837200.0       20.665745   91759200.0   \n",
       "2010-12-03        9.563414  342092800.0       20.765650   52622000.0   \n",
       "2010-12-06        9.645058  448481600.0       20.627316   36264200.0   \n",
       "2010-12-07        9.586614  391454000.0       20.650375   57860500.0   \n",
       "\n",
       "            AMZN:Adj Close  AMZN:Volume  GOOGL:Adj Close  GOOGL:Volume  \\\n",
       "Date                                                                     \n",
       "2010-12-01          8.8275  115402000.0        14.087989   150013836.0   \n",
       "2010-12-02          8.8265  110752000.0        14.274464   101814084.0   \n",
       "2010-12-03          8.7840   98150000.0        14.303920   105142752.0   \n",
       "2010-12-06          8.9025  113084000.0        14.437722    83668248.0   \n",
       "2010-12-07          8.8385  101542000.0        14.656900   121566312.0   \n",
       "\n",
       "            META:Adj Close  META:Volume  ...  CL=F:Adj Close  CL=F:Volume  \\\n",
       "Date                                     ...                                \n",
       "2010-12-01             NaN          NaN  ...       86.750000     340736.0   \n",
       "2010-12-02             NaN          NaN  ...       88.000000     330642.0   \n",
       "2010-12-03             NaN          NaN  ...       89.190002     354635.0   \n",
       "2010-12-06             NaN          NaN  ...       89.379997     293836.0   \n",
       "2010-12-07             NaN          NaN  ...       88.690002     462689.0   \n",
       "\n",
       "            ^GSPC:Adj Close  ^GSPC:Volume  ^VIX:Adj Close  ^VIX:Volume  \\\n",
       "Date                                                                     \n",
       "2010-12-01      1206.069946  4.548110e+09       21.360001          0.0   \n",
       "2010-12-02      1221.530029  4.970800e+09       19.389999          0.0   \n",
       "2010-12-03      1224.709961  3.735780e+09       18.010000          0.0   \n",
       "2010-12-06      1223.119995  3.527370e+09       18.020000          0.0   \n",
       "2010-12-07      1223.750000  6.970630e+09       17.990000          0.0   \n",
       "\n",
       "            DX-Y.NYB:Adj Close  DX-Y.NYB:Volume  HG=F:Adj Close  HG=F:Volume  \n",
       "Date                                                                          \n",
       "2010-12-01           80.709999              0.0           3.946       1301.0  \n",
       "2010-12-02           80.300003              0.0           3.977        907.0  \n",
       "2010-12-03           79.379997              0.0           3.995        543.0  \n",
       "2010-12-06           79.570000              0.0           4.004        377.0  \n",
       "2010-12-07           79.860001              0.0           4.044       1155.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Data cleaning and feature engineering the tickers dataframe:\n",
    "        - I only ned to know Adj Close and Volume numbers for relevant metrics per each stock\n",
    "        - The stocks of interest are:\n",
    "            - Stock that I am predicting for trading\n",
    "            - Probably some other related stocks (2-6 of them)\n",
    "            - Global market conditions indicators\n",
    "\"\"\"\n",
    "\n",
    "# a little before and ahead of datetime to ensure tech indicators cover full range\n",
    "start_date = datetime.datetime(2010, 12, 1)\n",
    "end_date = datetime.datetime(2023, 2, 1)\n",
    "\n",
    "prediction_ticker = [\"Ticker\", \"AAPL\"]\n",
    "relevant_tickers = [\"MSFT\", \"AMZN\", \"GOOGL\", \"META\", \"NVDA\"]\n",
    "global_market_tickers = [\"GC=F\", \"GLD\", \"CL=F\", \"^GSPC\", \"^VIX\", \"DX-Y.NYB\", \"HG=F\"]\n",
    "apple_prediction_tickers = prediction_ticker + relevant_tickers + global_market_tickers\n",
    "apple_df = tickers_df[apple_prediction_tickers]\n",
    "cols_to_keep = set([\"Adj Close\", \"Volume\"])\n",
    "remapped_columns = [f\"{outer}:{inner}\" for outer, inner in apple_df.columns]\n",
    "apple_cols_to_keep = [\"Ticker:Price\"] + [f\"{outer}:{inner}\" for outer, inner in apple_df.columns if inner in cols_to_keep]\n",
    "apple_df.columns = remapped_columns\n",
    "apple_df = apple_df[apple_cols_to_keep]\n",
    "apple_df = apple_df.iloc[1:]\n",
    "apple_df[\"Ticker:Price\"] = pd.to_datetime(apple_df[\"Ticker:Price\"])\n",
    "apple_df = apple_df[(apple_df[\"Ticker:Price\"] >= start_date) & (apple_df[\"Ticker:Price\"] <= end_date)]\n",
    "apple_df = apple_df.set_index(\"Ticker:Price\").rename_axis(\"Date\")\n",
    "\n",
    "\n",
    "nrow, ncol = apple_df.shape\n",
    "print(\"nrow\", nrow, \"ncol\", ncol)\n",
    "print(\"After some cleanup, here is the AAPL technical indicator dataframe:\")\n",
    "print()\n",
    "apple_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying all technical indicator data on AAPL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_period = 15\n",
    "long_period = 30\n",
    "\n",
    "# get the Y value: future average stock price\n",
    "apple_df[\"future_avg_price\"] = calculate_future_average_stock_price(apple_df[\"AAPL:Adj Close\"])\n",
    "cols = apple_df.columns\n",
    "for colname in cols:\n",
    "    if \"Volume\" in colname:\n",
    "        # get the ewn of volumes\n",
    "        apple_df[colname + \"_ewm_short\"] = apple_df[colname] / apple_df[colname].ewm(span=short_period, adjust=False).mean()\n",
    "        apple_df[colname + \"_ewm_long\"] = apple_df[colname] / apple_df[colname].ewm(span=long_period, adjust=False).mean()\n",
    "    elif \"Adj Close\" in colname:\n",
    "        # get RSI & MACD signal difference otherwise\n",
    "        apple_df[colname + \"_rsi\"] = calculate_rsi(apple_df[colname], period=14, use_exponential=True)\n",
    "        macd, signal = calculate_macd(apple_df[colname])\n",
    "        apple_df[colname + \"_macd_diff\"] = macd - signal\n",
    "\n",
    "apple_df = apple_df.drop([col for col in apple_df.columns if \"_\" not in col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>future_avg_price</th>\n",
       "      <th>AAPL:Adj Close_rsi</th>\n",
       "      <th>AAPL:Adj Close_macd_diff</th>\n",
       "      <th>AAPL:Volume_ewm_short</th>\n",
       "      <th>AAPL:Volume_ewm_long</th>\n",
       "      <th>MSFT:Adj Close_rsi</th>\n",
       "      <th>MSFT:Adj Close_macd_diff</th>\n",
       "      <th>MSFT:Volume_ewm_short</th>\n",
       "      <th>MSFT:Volume_ewm_long</th>\n",
       "      <th>AMZN:Adj Close_rsi</th>\n",
       "      <th>...</th>\n",
       "      <th>^VIX:Volume_ewm_short</th>\n",
       "      <th>^VIX:Volume_ewm_long</th>\n",
       "      <th>DX-Y.NYB:Adj Close_rsi</th>\n",
       "      <th>DX-Y.NYB:Adj Close_macd_diff</th>\n",
       "      <th>DX-Y.NYB:Volume_ewm_short</th>\n",
       "      <th>DX-Y.NYB:Volume_ewm_long</th>\n",
       "      <th>HG=F:Adj Close_rsi</th>\n",
       "      <th>HG=F:Adj Close_macd_diff</th>\n",
       "      <th>HG=F:Volume_ewm_short</th>\n",
       "      <th>HG=F:Volume_ewm_long</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-12-01</th>\n",
       "      <td>1.076100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-02</th>\n",
       "      <td>1.070352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002058</td>\n",
       "      <td>1.002201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.202170</td>\n",
       "      <td>1.219208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724586</td>\n",
       "      <td>0.711049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-03</th>\n",
       "      <td>1.073461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.753348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717266</td>\n",
       "      <td>0.713029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466833</td>\n",
       "      <td>0.442068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-06</th>\n",
       "      <td>1.067404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003071</td>\n",
       "      <td>0.988424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527655</td>\n",
       "      <td>0.508052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.354028</td>\n",
       "      <td>0.321290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-07</th>\n",
       "      <td>1.077959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.889362</td>\n",
       "      <td>0.870447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.858862</td>\n",
       "      <td>0.820637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.073270</td>\n",
       "      <td>0.985321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>89.877302</td>\n",
       "      <td>1.789046</td>\n",
       "      <td>0.774861</td>\n",
       "      <td>0.731899</td>\n",
       "      <td>76.000267</td>\n",
       "      <td>1.601311</td>\n",
       "      <td>0.940655</td>\n",
       "      <td>1.014999</td>\n",
       "      <td>73.782786</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.519546</td>\n",
       "      <td>-0.012555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.252497</td>\n",
       "      <td>0.010237</td>\n",
       "      <td>1.136464</td>\n",
       "      <td>0.846178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>91.689990</td>\n",
       "      <td>1.840992</td>\n",
       "      <td>1.009139</td>\n",
       "      <td>0.957247</td>\n",
       "      <td>75.746952</td>\n",
       "      <td>1.771554</td>\n",
       "      <td>0.769605</td>\n",
       "      <td>0.814267</td>\n",
       "      <td>79.809506</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.387755</td>\n",
       "      <td>0.014579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.738372</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>1.086049</td>\n",
       "      <td>0.828394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>68.518800</td>\n",
       "      <td>1.590925</td>\n",
       "      <td>0.925355</td>\n",
       "      <td>0.875941</td>\n",
       "      <td>56.930984</td>\n",
       "      <td>1.447532</td>\n",
       "      <td>0.775372</td>\n",
       "      <td>0.805523</td>\n",
       "      <td>67.792477</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.946210</td>\n",
       "      <td>0.060868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.239994</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>0.868789</td>\n",
       "      <td>0.665490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70.942175</td>\n",
       "      <td>1.427551</td>\n",
       "      <td>0.957951</td>\n",
       "      <td>0.907153</td>\n",
       "      <td>64.336897</td>\n",
       "      <td>1.489805</td>\n",
       "      <td>0.816429</td>\n",
       "      <td>0.835858</td>\n",
       "      <td>72.470053</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.024764</td>\n",
       "      <td>0.082774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.957367</td>\n",
       "      <td>-0.006613</td>\n",
       "      <td>0.966245</td>\n",
       "      <td>0.749324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>74.074352</td>\n",
       "      <td>1.314354</td>\n",
       "      <td>1.111413</td>\n",
       "      <td>1.064726</td>\n",
       "      <td>70.820560</td>\n",
       "      <td>1.746007</td>\n",
       "      <td>0.966224</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>76.828249</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.455065</td>\n",
       "      <td>0.043389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.635478</td>\n",
       "      <td>-0.016976</td>\n",
       "      <td>1.641792</td>\n",
       "      <td>1.366316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3064 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            future_avg_price  AAPL:Adj Close_rsi  AAPL:Adj Close_macd_diff  \\\n",
       "Date                                                                         \n",
       "2010-12-01          1.076100                 NaN                       NaN   \n",
       "2010-12-02          1.070352                 NaN                       NaN   \n",
       "2010-12-03          1.073461                 NaN                       NaN   \n",
       "2010-12-06          1.067404                 NaN                       NaN   \n",
       "2010-12-07          1.077959                 NaN                       NaN   \n",
       "...                      ...                 ...                       ...   \n",
       "2023-01-26               NaN           89.877302                  1.789046   \n",
       "2023-01-27               NaN           91.689990                  1.840992   \n",
       "2023-01-30               NaN           68.518800                  1.590925   \n",
       "2023-01-31               NaN           70.942175                  1.427551   \n",
       "2023-02-01               NaN           74.074352                  1.314354   \n",
       "\n",
       "            AAPL:Volume_ewm_short  AAPL:Volume_ewm_long  MSFT:Adj Close_rsi  \\\n",
       "Date                                                                          \n",
       "2010-12-01               1.000000              1.000000                 NaN   \n",
       "2010-12-02               1.002058              1.002201                 NaN   \n",
       "2010-12-03               0.765458              0.753348                 NaN   \n",
       "2010-12-06               1.003071              0.988424                 NaN   \n",
       "2010-12-07               0.889362              0.870447                 NaN   \n",
       "...                           ...                   ...                 ...   \n",
       "2023-01-26               0.774861              0.731899           76.000267   \n",
       "2023-01-27               1.009139              0.957247           75.746952   \n",
       "2023-01-30               0.925355              0.875941           56.930984   \n",
       "2023-01-31               0.957951              0.907153           64.336897   \n",
       "2023-02-01               1.111413              1.064726           70.820560   \n",
       "\n",
       "            MSFT:Adj Close_macd_diff  MSFT:Volume_ewm_short  \\\n",
       "Date                                                          \n",
       "2010-12-01                       NaN               1.000000   \n",
       "2010-12-02                       NaN               1.202170   \n",
       "2010-12-03                       NaN               0.717266   \n",
       "2010-12-06                       NaN               0.527655   \n",
       "2010-12-07                       NaN               0.858862   \n",
       "...                              ...                    ...   \n",
       "2023-01-26                  1.601311               0.940655   \n",
       "2023-01-27                  1.771554               0.769605   \n",
       "2023-01-30                  1.447532               0.775372   \n",
       "2023-01-31                  1.489805               0.816429   \n",
       "2023-02-01                  1.746007               0.966224   \n",
       "\n",
       "            MSFT:Volume_ewm_long  AMZN:Adj Close_rsi  ...  \\\n",
       "Date                                                  ...   \n",
       "2010-12-01              1.000000                 NaN  ...   \n",
       "2010-12-02              1.219208                 NaN  ...   \n",
       "2010-12-03              0.713029                 NaN  ...   \n",
       "2010-12-06              0.508052                 NaN  ...   \n",
       "2010-12-07              0.820637                 NaN  ...   \n",
       "...                          ...                 ...  ...   \n",
       "2023-01-26              1.014999           73.782786  ...   \n",
       "2023-01-27              0.814267           79.809506  ...   \n",
       "2023-01-30              0.805523           67.792477  ...   \n",
       "2023-01-31              0.835858           72.470053  ...   \n",
       "2023-02-01              0.985455           76.828249  ...   \n",
       "\n",
       "            ^VIX:Volume_ewm_short  ^VIX:Volume_ewm_long  \\\n",
       "Date                                                      \n",
       "2010-12-01                    NaN                   NaN   \n",
       "2010-12-02                    NaN                   NaN   \n",
       "2010-12-03                    NaN                   NaN   \n",
       "2010-12-06                    NaN                   NaN   \n",
       "2010-12-07                    NaN                   NaN   \n",
       "...                           ...                   ...   \n",
       "2023-01-26                    NaN                   NaN   \n",
       "2023-01-27                    NaN                   NaN   \n",
       "2023-01-30                    NaN                   NaN   \n",
       "2023-01-31                    NaN                   NaN   \n",
       "2023-02-01                    NaN                   NaN   \n",
       "\n",
       "            DX-Y.NYB:Adj Close_rsi  DX-Y.NYB:Adj Close_macd_diff  \\\n",
       "Date                                                               \n",
       "2010-12-01                     NaN                           NaN   \n",
       "2010-12-02                     NaN                           NaN   \n",
       "2010-12-03                     NaN                           NaN   \n",
       "2010-12-06                     NaN                           NaN   \n",
       "2010-12-07                     NaN                           NaN   \n",
       "...                            ...                           ...   \n",
       "2023-01-26               29.519546                     -0.012555   \n",
       "2023-01-27               37.387755                      0.014579   \n",
       "2023-01-30               50.946210                      0.060868   \n",
       "2023-01-31               45.024764                      0.082774   \n",
       "2023-02-01               28.455065                      0.043389   \n",
       "\n",
       "            DX-Y.NYB:Volume_ewm_short  DX-Y.NYB:Volume_ewm_long  \\\n",
       "Date                                                              \n",
       "2010-12-01                        NaN                       NaN   \n",
       "2010-12-02                        NaN                       NaN   \n",
       "2010-12-03                        NaN                       NaN   \n",
       "2010-12-06                        NaN                       NaN   \n",
       "2010-12-07                        NaN                       NaN   \n",
       "...                               ...                       ...   \n",
       "2023-01-26                        0.0                       0.0   \n",
       "2023-01-27                        0.0                       0.0   \n",
       "2023-01-30                        0.0                       0.0   \n",
       "2023-01-31                        0.0                       0.0   \n",
       "2023-02-01                        0.0                       0.0   \n",
       "\n",
       "            HG=F:Adj Close_rsi  HG=F:Adj Close_macd_diff  \\\n",
       "Date                                                       \n",
       "2010-12-01                 NaN                       NaN   \n",
       "2010-12-02                 NaN                       NaN   \n",
       "2010-12-03                 NaN                       NaN   \n",
       "2010-12-06                 NaN                       NaN   \n",
       "2010-12-07                 NaN                       NaN   \n",
       "...                        ...                       ...   \n",
       "2023-01-26           69.252497                  0.010237   \n",
       "2023-01-27           54.738372                  0.003587   \n",
       "2023-01-30           50.239994                 -0.003125   \n",
       "2023-01-31           50.957367                 -0.006613   \n",
       "2023-02-01           31.635478                 -0.016976   \n",
       "\n",
       "            HG=F:Volume_ewm_short  HG=F:Volume_ewm_long  \n",
       "Date                                                     \n",
       "2010-12-01               1.000000              1.000000  \n",
       "2010-12-02               0.724586              0.711049  \n",
       "2010-12-03               0.466833              0.442068  \n",
       "2010-12-06               0.354028              0.321290  \n",
       "2010-12-07               1.073270              0.985321  \n",
       "...                           ...                   ...  \n",
       "2023-01-26               1.136464              0.846178  \n",
       "2023-01-27               1.086049              0.828394  \n",
       "2023-01-30               0.868789              0.665490  \n",
       "2023-01-31               0.966245              0.749324  \n",
       "2023-02-01               1.641792              1.366316  \n",
       "\n",
       "[3064 rows x 53 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>future_avg_price</th>\n",
       "      <th>AAPL:Adj Close_rsi</th>\n",
       "      <th>AAPL:Adj Close_macd_diff</th>\n",
       "      <th>AAPL:Volume_ewm_short</th>\n",
       "      <th>AAPL:Volume_ewm_long</th>\n",
       "      <th>MSFT:Adj Close_rsi</th>\n",
       "      <th>MSFT:Adj Close_macd_diff</th>\n",
       "      <th>MSFT:Volume_ewm_short</th>\n",
       "      <th>MSFT:Volume_ewm_long</th>\n",
       "      <th>AMZN:Adj Close_rsi</th>\n",
       "      <th>...</th>\n",
       "      <th>^VIX:Volume_ewm_short</th>\n",
       "      <th>^VIX:Volume_ewm_long</th>\n",
       "      <th>DX-Y.NYB:Adj Close_rsi</th>\n",
       "      <th>DX-Y.NYB:Adj Close_macd_diff</th>\n",
       "      <th>DX-Y.NYB:Volume_ewm_short</th>\n",
       "      <th>DX-Y.NYB:Volume_ewm_long</th>\n",
       "      <th>HG=F:Adj Close_rsi</th>\n",
       "      <th>HG=F:Adj Close_macd_diff</th>\n",
       "      <th>HG=F:Volume_ewm_short</th>\n",
       "      <th>HG=F:Volume_ewm_long</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-12-01</th>\n",
       "      <td>1.076100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-02</th>\n",
       "      <td>1.070352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002058</td>\n",
       "      <td>1.002201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.202170</td>\n",
       "      <td>1.219208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724586</td>\n",
       "      <td>0.711049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-03</th>\n",
       "      <td>1.073461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.753348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717266</td>\n",
       "      <td>0.713029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466833</td>\n",
       "      <td>0.442068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-06</th>\n",
       "      <td>1.067404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003071</td>\n",
       "      <td>0.988424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527655</td>\n",
       "      <td>0.508052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.354028</td>\n",
       "      <td>0.321290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-07</th>\n",
       "      <td>1.077959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.889362</td>\n",
       "      <td>0.870447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.858862</td>\n",
       "      <td>0.820637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.073270</td>\n",
       "      <td>0.985321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            future_avg_price  AAPL:Adj Close_rsi  AAPL:Adj Close_macd_diff  \\\n",
       "Date                                                                         \n",
       "2010-12-01          1.076100                 NaN                       NaN   \n",
       "2010-12-02          1.070352                 NaN                       NaN   \n",
       "2010-12-03          1.073461                 NaN                       NaN   \n",
       "2010-12-06          1.067404                 NaN                       NaN   \n",
       "2010-12-07          1.077959                 NaN                       NaN   \n",
       "\n",
       "            AAPL:Volume_ewm_short  AAPL:Volume_ewm_long  MSFT:Adj Close_rsi  \\\n",
       "Date                                                                          \n",
       "2010-12-01               1.000000              1.000000                 NaN   \n",
       "2010-12-02               1.002058              1.002201                 NaN   \n",
       "2010-12-03               0.765458              0.753348                 NaN   \n",
       "2010-12-06               1.003071              0.988424                 NaN   \n",
       "2010-12-07               0.889362              0.870447                 NaN   \n",
       "\n",
       "            MSFT:Adj Close_macd_diff  MSFT:Volume_ewm_short  \\\n",
       "Date                                                          \n",
       "2010-12-01                       NaN               1.000000   \n",
       "2010-12-02                       NaN               1.202170   \n",
       "2010-12-03                       NaN               0.717266   \n",
       "2010-12-06                       NaN               0.527655   \n",
       "2010-12-07                       NaN               0.858862   \n",
       "\n",
       "            MSFT:Volume_ewm_long  AMZN:Adj Close_rsi  ...  \\\n",
       "Date                                                  ...   \n",
       "2010-12-01              1.000000                 NaN  ...   \n",
       "2010-12-02              1.219208                 NaN  ...   \n",
       "2010-12-03              0.713029                 NaN  ...   \n",
       "2010-12-06              0.508052                 NaN  ...   \n",
       "2010-12-07              0.820637                 NaN  ...   \n",
       "\n",
       "            ^VIX:Volume_ewm_short  ^VIX:Volume_ewm_long  \\\n",
       "Date                                                      \n",
       "2010-12-01                    NaN                   NaN   \n",
       "2010-12-02                    NaN                   NaN   \n",
       "2010-12-03                    NaN                   NaN   \n",
       "2010-12-06                    NaN                   NaN   \n",
       "2010-12-07                    NaN                   NaN   \n",
       "\n",
       "            DX-Y.NYB:Adj Close_rsi  DX-Y.NYB:Adj Close_macd_diff  \\\n",
       "Date                                                               \n",
       "2010-12-01                     NaN                           NaN   \n",
       "2010-12-02                     NaN                           NaN   \n",
       "2010-12-03                     NaN                           NaN   \n",
       "2010-12-06                     NaN                           NaN   \n",
       "2010-12-07                     NaN                           NaN   \n",
       "\n",
       "            DX-Y.NYB:Volume_ewm_short  DX-Y.NYB:Volume_ewm_long  \\\n",
       "Date                                                              \n",
       "2010-12-01                        NaN                       NaN   \n",
       "2010-12-02                        NaN                       NaN   \n",
       "2010-12-03                        NaN                       NaN   \n",
       "2010-12-06                        NaN                       NaN   \n",
       "2010-12-07                        NaN                       NaN   \n",
       "\n",
       "            HG=F:Adj Close_rsi  HG=F:Adj Close_macd_diff  \\\n",
       "Date                                                       \n",
       "2010-12-01                 NaN                       NaN   \n",
       "2010-12-02                 NaN                       NaN   \n",
       "2010-12-03                 NaN                       NaN   \n",
       "2010-12-06                 NaN                       NaN   \n",
       "2010-12-07                 NaN                       NaN   \n",
       "\n",
       "            HG=F:Volume_ewm_short  HG=F:Volume_ewm_long  \n",
       "Date                                                     \n",
       "2010-12-01               1.000000              1.000000  \n",
       "2010-12-02               0.724586              0.711049  \n",
       "2010-12-03               0.466833              0.442068  \n",
       "2010-12-06               0.354028              0.321290  \n",
       "2010-12-07               1.073270              0.985321  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "government_data.head()\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on datetime64[ns] and object columns for key 'Date'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m government_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisclosure_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(government_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisclosure_date\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n\u001b[0;32m      6\u001b[0m mergeaapl_data \u001b[38;5;241m=\u001b[39m government_data[government_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 8\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmergeaapl_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdisclosure_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use 'Date' from apple_df\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdisclosure_date\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use 'disclosure_date' from government_data\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print(merged_df)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abhin\\miniconda3\\envs\\stockpredictions\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    156\u001b[0m         left_df,\n\u001b[0;32m    157\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\abhin\\miniconda3\\envs\\stockpredictions\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:807\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[0;32m    805\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\abhin\\miniconda3\\envs\\stockpredictions\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1512\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m-> 1512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on datetime64[ns] and object columns for key 'Date'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "temp_df = apple_df\n",
    "government_data = pd.read_csv(\"congressional_data.csv\")\n",
    "\n",
    "government_data['disclosure_date'] = pd.to_datetime(government_data['disclosure_date'], format='%m/%d/%Y').dt.date\n",
    "\n",
    "mergeaapl_data = government_data[government_data[\"ticker\"] == \"AAPL\"]\n",
    "\n",
    "merged_df = pd.merge(temp_df, mergeaapl_data[['amount', 'disclosure_date']], \n",
    "                     left_on=[\"Date\"],  # Use 'Date' from apple_df\n",
    "                     right_on=[\"disclosure_date\"],  # Use 'disclosure_date' from government_data\n",
    "                     how='left')\n",
    "\n",
    "# print(merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stockpredictions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
