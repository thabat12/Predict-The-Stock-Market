{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all the SP500 ticker symbols through Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 ticker symbols:\n",
      "['MMM', 'AOS', 'ABT', 'ABBV', 'ACN']\n"
     ]
    }
   ],
   "source": [
    "## sp500 stocks \n",
    "\n",
    "all_tickers_xpath = '//span[text() = \"S&P 500 component stocks\"]/following::tbody[1]/tr/td[1]/a'\n",
    "soup = BeautifulSoup(requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies').content, 'html.parser')\n",
    "dom = etree.HTML(str(soup))\n",
    "\n",
    "# find all tickers\n",
    "all_tickers = [i.text for i in dom.xpath(all_tickers_xpath)]\n",
    "\n",
    "# look at the first 5 ticker symbols\n",
    "print('The first 5 ticker symbols:')\n",
    "print(all_tickers[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all stock market data for every ticker symbol on the SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  503 of 503 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "['BF.B']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 1925-12-20 -> 2024-11-25)')\n",
      "['BRK.B']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n"
     ]
    }
   ],
   "source": [
    "# yfinance is very convenient and allows us to do this in one function call\n",
    "group_tickers = yf.download(' '.join(all_tickers), group_by='tickers')\n",
    "group_tickers.to_csv('stock_ticker_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 15834 Number of cols: 3018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th colspan=\"6\" halign=\"left\">WEC</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MTB</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">DFS</th>\n",
       "      <th colspan=\"6\" halign=\"left\">COO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>...</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-19</th>\n",
       "      <td>99.300003</td>\n",
       "      <td>99.300003</td>\n",
       "      <td>98.360001</td>\n",
       "      <td>99.050003</td>\n",
       "      <td>99.050003</td>\n",
       "      <td>1582600.0</td>\n",
       "      <td>211.710007</td>\n",
       "      <td>214.690002</td>\n",
       "      <td>211.210007</td>\n",
       "      <td>213.710007</td>\n",
       "      <td>...</td>\n",
       "      <td>169.449997</td>\n",
       "      <td>172.500000</td>\n",
       "      <td>171.801102</td>\n",
       "      <td>1225700.0</td>\n",
       "      <td>98.940002</td>\n",
       "      <td>99.900002</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>99.050003</td>\n",
       "      <td>99.050003</td>\n",
       "      <td>887800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-20</th>\n",
       "      <td>98.790001</td>\n",
       "      <td>99.309998</td>\n",
       "      <td>98.639999</td>\n",
       "      <td>99.269997</td>\n",
       "      <td>99.269997</td>\n",
       "      <td>1934300.0</td>\n",
       "      <td>214.750000</td>\n",
       "      <td>214.750000</td>\n",
       "      <td>211.399994</td>\n",
       "      <td>213.520004</td>\n",
       "      <td>...</td>\n",
       "      <td>171.759995</td>\n",
       "      <td>172.770004</td>\n",
       "      <td>172.070007</td>\n",
       "      <td>1968600.0</td>\n",
       "      <td>98.699997</td>\n",
       "      <td>99.190002</td>\n",
       "      <td>97.980003</td>\n",
       "      <td>99.080002</td>\n",
       "      <td>99.080002</td>\n",
       "      <td>898900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-21</th>\n",
       "      <td>99.050003</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>98.650002</td>\n",
       "      <td>100.959999</td>\n",
       "      <td>100.959999</td>\n",
       "      <td>1928800.0</td>\n",
       "      <td>213.630005</td>\n",
       "      <td>218.919998</td>\n",
       "      <td>212.979996</td>\n",
       "      <td>216.619995</td>\n",
       "      <td>...</td>\n",
       "      <td>172.490005</td>\n",
       "      <td>174.910004</td>\n",
       "      <td>174.910004</td>\n",
       "      <td>1904800.0</td>\n",
       "      <td>99.080002</td>\n",
       "      <td>100.040001</td>\n",
       "      <td>98.129997</td>\n",
       "      <td>99.910004</td>\n",
       "      <td>99.910004</td>\n",
       "      <td>992400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-22</th>\n",
       "      <td>101.160004</td>\n",
       "      <td>101.430000</td>\n",
       "      <td>100.570000</td>\n",
       "      <td>100.660004</td>\n",
       "      <td>100.660004</td>\n",
       "      <td>1304600.0</td>\n",
       "      <td>216.250000</td>\n",
       "      <td>221.520004</td>\n",
       "      <td>216.220001</td>\n",
       "      <td>221.119995</td>\n",
       "      <td>...</td>\n",
       "      <td>174.779999</td>\n",
       "      <td>179.289993</td>\n",
       "      <td>179.289993</td>\n",
       "      <td>1063000.0</td>\n",
       "      <td>99.949997</td>\n",
       "      <td>101.190002</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>100.800003</td>\n",
       "      <td>100.800003</td>\n",
       "      <td>1140400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-25</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.589996</td>\n",
       "      <td>100.370003</td>\n",
       "      <td>101.349998</td>\n",
       "      <td>101.349998</td>\n",
       "      <td>2264847.0</td>\n",
       "      <td>221.500000</td>\n",
       "      <td>225.699997</td>\n",
       "      <td>221.524994</td>\n",
       "      <td>221.949997</td>\n",
       "      <td>...</td>\n",
       "      <td>180.500000</td>\n",
       "      <td>182.669998</td>\n",
       "      <td>182.669998</td>\n",
       "      <td>1841820.0</td>\n",
       "      <td>101.760002</td>\n",
       "      <td>103.320000</td>\n",
       "      <td>101.500000</td>\n",
       "      <td>102.400002</td>\n",
       "      <td>102.400002</td>\n",
       "      <td>2559683.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3018 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker             WEC                                                  \\\n",
       "Price             Open        High         Low       Close   Adj Close   \n",
       "Date                                                                     \n",
       "2024-11-19   99.300003   99.300003   98.360001   99.050003   99.050003   \n",
       "2024-11-20   98.790001   99.309998   98.639999   99.269997   99.269997   \n",
       "2024-11-21   99.050003  101.000000   98.650002  100.959999  100.959999   \n",
       "2024-11-22  101.160004  101.430000  100.570000  100.660004  100.660004   \n",
       "2024-11-25  101.000000  101.589996  100.370003  101.349998  101.349998   \n",
       "\n",
       "Ticker                        MTB                                      ...  \\\n",
       "Price          Volume        Open        High         Low       Close  ...   \n",
       "Date                                                                   ...   \n",
       "2024-11-19  1582600.0  211.710007  214.690002  211.210007  213.710007  ...   \n",
       "2024-11-20  1934300.0  214.750000  214.750000  211.399994  213.520004  ...   \n",
       "2024-11-21  1928800.0  213.630005  218.919998  212.979996  216.619995  ...   \n",
       "2024-11-22  1304600.0  216.250000  221.520004  216.220001  221.119995  ...   \n",
       "2024-11-25  2264847.0  221.500000  225.699997  221.524994  221.949997  ...   \n",
       "\n",
       "Ticker             DFS                                            COO  \\\n",
       "Price              Low       Close   Adj Close     Volume        Open   \n",
       "Date                                                                    \n",
       "2024-11-19  169.449997  172.500000  171.801102  1225700.0   98.940002   \n",
       "2024-11-20  171.759995  172.770004  172.070007  1968600.0   98.699997   \n",
       "2024-11-21  172.490005  174.910004  174.910004  1904800.0   99.080002   \n",
       "2024-11-22  174.779999  179.289993  179.289993  1063000.0   99.949997   \n",
       "2024-11-25  180.500000  182.669998  182.669998  1841820.0  101.760002   \n",
       "\n",
       "Ticker                                                                 \n",
       "Price             High         Low       Close   Adj Close     Volume  \n",
       "Date                                                                   \n",
       "2024-11-19   99.900002   98.000000   99.050003   99.050003   887800.0  \n",
       "2024-11-20   99.190002   97.980003   99.080002   99.080002   898900.0  \n",
       "2024-11-21  100.040001   98.129997   99.910004   99.910004   992400.0  \n",
       "2024-11-22  101.190002   99.500000  100.800003  100.800003  1140400.0  \n",
       "2024-11-25  103.320000  101.500000  102.400002  102.400002  2559683.0  \n",
       "\n",
       "[5 rows x 3018 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some summary statistics for the ticker data\n",
    "rows_cnt, col_cnt = np.shape(group_tickers)\n",
    "print('Number of rows:', rows_cnt, 'Number of cols:', col_cnt)\n",
    "\n",
    "# see the last bit of data for the group ticker symbols\n",
    "group_tickers.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering all required textual data (for sentiment/ market condition embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am working on 5 years of data for all the tickers given by the SP500.\n",
    "\n",
    "# literally all reddit data held in the Pushshift api dumps for years up to 2023:\n",
    "#   you will need Torrent to deal with this data\n",
    "# https://www.reddit.com/r/pushshift/comments/1akrhg3/separate_dump_files_for_the_top_40k_subreddits/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Reading CSV data of stock market and formatting</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Unfortunately, 500 stock indicators is too much data, so we have to shorten this list to a smaller subset of stocks to study. We will focus on the top 25 stocks of SP500.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_stocks = '''AAPL MSFT AMZN NVDA GOOGL BRK.A GOOG TSLA META XOM UNH JNJ JPM V PG MA CVX HD ABBV LLY MRK AVGO PEP KO PFE'''\n",
    "top_stocks = top_stocks.split(' ')\n",
    "\n",
    "# subset the dataset to the rows that contain the stock symbols\n",
    "data_subset = data[data['Ticker'].isin(top_stocks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data_subset.groupby('Ticker')\n",
    "# this example group will just be the sample dataset that\n",
    "# we may do calculations with \n",
    "example_group = grouped.get_group(top_stocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finanicial indicator functions\n",
    "# note that these are indented to work with ONE key value\n",
    "# ex. ONLY DATES means that we must group by stock ticker\n",
    "# note: TICKERS will not make sense for these functions as keys\n",
    "\n",
    "def check_series_numeric(column) -> bool:\n",
    "    not_numeric = column.apply(pd.to_numeric, errors = 'coerce').isna().all()\n",
    "    # if the data is not numeric, the test failed \n",
    "    return not not_numeric\n",
    "\n",
    "def calculate_sma(column, period = 10):\n",
    "    if not check_series_numeric(column):\n",
    "        return column\n",
    "    sma = column.rolling(period).mean()\n",
    "    return pd.Series(sma, index= column.index, name = 'SMA')\n",
    "\n",
    "def calculate_ema(column, period = 10):\n",
    "    if not check_series_numeric(column):\n",
    "        return column\n",
    "    ema = column.ewm(span = period, min_periods = period - 1).mean()\n",
    "    return pd.Series(ema, index = column.index, name = 'EMA')\n",
    "\n",
    "# formula for RSI: \n",
    "'''\n",
    "    let RS = average gain / average loss   \n",
    "    RSI = 100 - 100 / (1 - RS)\n",
    "\n",
    "    some things to look out for: \n",
    "        - using exponential weighted means on the average\n",
    "            gains and losses made the RSI value much more\n",
    "            sensitive and fluctuating more based on price\n",
    "            changes\n",
    "        - using simple averages made the RSI value more \n",
    "            smoothed out\n",
    "\n",
    "    keyword argument options:\n",
    "        - period: type int\n",
    "        - use_exponential: type bool\n",
    "\n",
    "'''\n",
    "def calculate_rsi(column, *args, **kwargs):\n",
    "    rsi = column.rolling(14).apply(lambda x: calculate_rsi_helper(x, *args, **kwargs)).astype(float)\n",
    "    return pd.Series(rsi, index = column.index, name = 'RSI')\n",
    "\n",
    "def calculate_rsi_helper(column, period = 14, use_exponential = False):\n",
    "    if not check_series_numeric(column):\n",
    "        return column \n",
    "\n",
    "    column = column.astype(float)\n",
    "    # find differences in prices\n",
    "    differences = column.diff() \n",
    "\n",
    "    # clip, but center off of zero value\n",
    "    gain = differences.clip(lower = 0.01)\n",
    "    loss = differences.clip(upper = -0.01)\n",
    "\n",
    "    avg_gain = gain.mean()\n",
    "    avg_loss = loss.mean()\n",
    "\n",
    "    if use_exponential:\n",
    "        # get the exponential weighted mean of the very last element in this current rolling window\n",
    "        avg_gain = gain.ewm(span = period, min_periods = period - 1).mean()[-1]\n",
    "        avg_loss = loss.ewm(span = period, min_periods = period - 1).mean()[-1]\n",
    "\n",
    "    RS = avg_gain / avg_loss \n",
    "    RSI = 100 - 100 / (1 - RS)\n",
    "\n",
    "    return RSI\n",
    "\n",
    "'''\n",
    "    MACD (moving average convergence/ divergence) shows the relationship\n",
    "    between two exponential moving averages and comparing this to the \n",
    "    9-day EMA line \n",
    "\n",
    "    MACD = 12-period EMA - 26-period EMA \n",
    "    Signal = 9-period EMA - 26-period EMA\n",
    "'''\n",
    "def calculate_macd(column, long_period = 26, short_period = 12, signal_period = 9) -> tuple[object, object]:\n",
    "    if not check_series_numeric(column):\n",
    "        return column \n",
    "    \n",
    "    ewm_short = example_group['Adj Close'].ewm(span = short_period, min_periods = 11).mean()\n",
    "    ewm_long = example_group['Adj Close'].ewm(span = long_period, min_periods = 25).mean()\n",
    "\n",
    "    # returns the macd \n",
    "    macd = (ewm_short - ewm_long).astype(float)\n",
    "\n",
    "    # returns the signal line\n",
    "    ewm_signal = example_group['Adj Close'].ewm(span = signal_period, min_periods = 8).mean()\n",
    "    signal = (ewm_signal - ewm_long).astype(float)\n",
    "\n",
    "\n",
    "    macd = pd.Series(macd, index = column.index, name = 'MACD')\n",
    "    signal = pd.Series(signal, index = column.index, name = 'MACD-SIGNAL')\n",
    "    return macd, signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped ticker: BRK.A\n"
     ]
    }
   ],
   "source": [
    "# TODO: apply this process concurrently or parallel if possible, then we can get\n",
    "# even more data available to us\n",
    "dataframes = []\n",
    "for ticker in top_stocks:\n",
    "    cur = None\n",
    "    try:\n",
    "        cur = grouped.get_group(ticker)\n",
    "    except:\n",
    "        print('skipped ticker:', ticker)\n",
    "        continue \n",
    "\n",
    "    stock_data = cur['Adj Close']\n",
    "    sma = calculate_sma(stock_data)\n",
    "    ema = calculate_ema(stock_data)\n",
    "    rsi = calculate_rsi(stock_data)\n",
    "    macd, signal_macd = calculate_macd(stock_data)\n",
    "\n",
    "    overall = pd.DataFrame([sma, ema, rsi, macd, signal_macd]).T\n",
    "    res = pd.merge(cur, overall, on='Date')\n",
    "\n",
    "    res = res.set_index([res.index, res['Ticker']]).drop('Ticker', axis = 1)\n",
    "\n",
    "    dataframes.append(res)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Transforming indicators to give us values that are a bit more useful</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Each entry of stocks are associated with the current day and the ticker symbol</li>\n",
    "    <li>We may search through top comments or posts through Pushshift to search for stock ticker mentions per day and stock</li>\n",
    "    <li>In order to load numerous http requests, we are using asyncio for concurrently loading data</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert date time string into epoch format for pushshift\n",
    "def str_index_to_epoch(s: str, days_after = 1) -> tuple[int, int]:\n",
    "    s = str(s)\n",
    "    s = s.split('-')\n",
    "    yr = int(s[0])\n",
    "    mo = int(s[1])\n",
    "    day = int(s[2].split(' ')[0])\n",
    "    # the yahoo finance data is given as EST time\n",
    "    today = datetime.datetime(yr, mo, day)\n",
    "    tomorrow = today + relativedelta(days = days_after)\n",
    "\n",
    "    print('today', today, 'tomorrow', tomorrow, 'after', days_after)\n",
    "    return (int(today.timestamp()), int(tomorrow.timestamp()))\n",
    "\n",
    "def index_str_to_datetime(s: str, split='-'):\n",
    "    # get anything that is before a space, to isolate the current search thingy\n",
    "    s = s.split(' ')[0]\n",
    "    vals = [int(i) for i in s.split(split)]\n",
    "\n",
    "    return datetime.datetime(year=vals[0], month=vals[1], day=vals[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link(X, subreddit = 'stocks', size = 25, days_after = 1):\n",
    "    subreddit = subreddit\n",
    "    ticker = X['Ticker']\n",
    "    date_after, date_before = str_index_to_epoch(X.name, days_after=days_after)\n",
    "    size = size\n",
    "\n",
    "    req_string_reddit_comments = f'https://api.pushshift.io/reddit/search/comment/?q={ticker}&subreddit={subreddit}&size={size}&after={date_after}&before={date_before}&fields=body&frequency=day'\n",
    "    \n",
    "    return req_string_reddit_comments\n",
    "\n",
    "def create_query_link(argument_dict, type = 'comment'):\n",
    "    args = []\n",
    "    for argument in argument_dict:\n",
    "        args.append(argument)\n",
    "        args.append('=')\n",
    "        args.append(argument_dict[argument])\n",
    "        args.append('&')\n",
    "\n",
    "        query_string = ''.join(args[:-1])\n",
    "    return f'https://api.pushshift.io/reddit/{type}/search/?{query_string}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can simply use the api to get all date ranges for the stock market in one link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836 days to search for\n",
      "https://api.pushshift.io/reddit/comment/search/?q=AAPL&subreddit=stocks&after=1609740000&before=1681966800&size=500&count=50&sort=created_utc&sort_type=asc\n"
     ]
    }
   ],
   "source": [
    "# using ticker aapl as the current symbol\n",
    "stock_data = data.query('Ticker == \"AAPL\"').reset_index().set_index('Date')\n",
    "start_date, end_date = stock_data.iloc[0].name, stock_data.iloc[-1].name\n",
    "start_date, end_date = index_str_to_datetime(str(start_date)), index_str_to_datetime(str(end_date))\n",
    "\n",
    "period = (end_date - start_date).days\n",
    "print(period, 'days to search for')\n",
    "\n",
    "args = {\n",
    "    'q': 'AAPL',\n",
    "    'subreddit': 'stocks',\n",
    "    'after': str(int(start_date.timestamp())),\n",
    "    'before': str(int((end_date.timestamp()))),\n",
    "    'size': str(500),\n",
    "    'count': str(50),\n",
    "    'sort':'created_utc',\n",
    "    'sort_type': 'asc'\n",
    "}\n",
    "\n",
    "link = create_query_link(args)\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request # 1\n",
      "request # 2\n",
      "request # 3\n",
      "request # 4\n",
      "request # 5\n",
      "request # 6\n",
      "request # 7\n",
      "request # 8\n",
      "request # 9\n",
      "request # 10\n",
      "request # 11\n",
      "request # 12\n",
      "request # 13\n",
      "request # 14\n",
      "request # 15\n",
      "request # 16\n",
      "request # 17\n",
      "request # 18\n",
      "request # 19\n",
      "request # 20\n"
     ]
    }
   ],
   "source": [
    "import threading \n",
    "\n",
    "dataframes = []\n",
    "\n",
    "def roll_apply(window):\n",
    "    print(window)\n",
    "\n",
    "def add_to_dataframes(start, end, counter):\n",
    "    after = index_str_to_datetime(str(start)).timestamp()\n",
    "    before = index_str_to_datetime(str(end)).timestamp()\n",
    "\n",
    "    args = {\n",
    "    'q': 'AAPL',\n",
    "    'subreddit': 'stocks',\n",
    "    'after': str(int(after)),\n",
    "    'before': str(int(before)),\n",
    "    'size': str(500),\n",
    "    'count': str(50),\n",
    "    'sort':'created_utc',\n",
    "    'sort_type': 'asc'\n",
    "    }\n",
    "\n",
    "    print('request #', counter)\n",
    "\n",
    "    r = requests.get(create_query_link(args))\n",
    "    result = json.loads(r.text)['data']\n",
    "    dataframes.append(pd.DataFrame(result))\n",
    "\n",
    "counter = 1\n",
    "period = 30\n",
    "\n",
    "cur_threads = []\n",
    "for i in range(0, len(stock_data), period):\n",
    "    start = stock_data.iloc[i].name\n",
    "    end = stock_data.iloc[min(len(stock_data)-1,i + period)].name\n",
    "\n",
    "    thread = threading.Thread(target=add_to_dataframes, args=(start, end, counter))\n",
    "    thread.start()\n",
    "    cur_threads.append(thread)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "for thread in cur_threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>utc_datetime_str</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You're gonna wanna add PLTR by the EOY.  Other...</td>\n",
       "      <td>2021-02-17 05:58:16</td>\n",
       "      <td>2021-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I started a 1000$ (1087$ to be exact) trading ...</td>\n",
       "      <td>2021-02-17 05:56:23</td>\n",
       "      <td>2021-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL and MSFT are like bank accounts with 20-4...</td>\n",
       "      <td>2021-02-17 05:33:25</td>\n",
       "      <td>2021-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Message unclear. YOLO life savings on AAPL at ...</td>\n",
       "      <td>2021-02-17 05:31:52</td>\n",
       "      <td>2021-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leaps on AAPL are pricey.  If you’re going in ...</td>\n",
       "      <td>2021-02-17 05:27:41</td>\n",
       "      <td>2021-02-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>I don’t mean market consensus “undeniable winn...</td>\n",
       "      <td>2023-04-11 13:48:42</td>\n",
       "      <td>2023-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I had 6680 shares of Waste Management in 2012 ...</td>\n",
       "      <td>2023-04-11 13:17:25</td>\n",
       "      <td>2023-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Portfolio 1:  \\nCSPX, VXUS  \\nAAPL, ABNB, AZN,...</td>\n",
       "      <td>2023-04-11 12:24:42</td>\n",
       "      <td>2023-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AAPL. Strong buybacks and good dividend backed...</td>\n",
       "      <td>2023-04-11 11:21:45</td>\n",
       "      <td>2023-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>I'd skip Tesla and split it evenly between MSF...</td>\n",
       "      <td>2023-04-11 06:00:03</td>\n",
       "      <td>2023-04-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9228 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body     utc_datetime_str  \\\n",
       "0   You're gonna wanna add PLTR by the EOY.  Other...  2021-02-17 05:58:16   \n",
       "1   I started a 1000$ (1087$ to be exact) trading ...  2021-02-17 05:56:23   \n",
       "2   AAPL and MSFT are like bank accounts with 20-4...  2021-02-17 05:33:25   \n",
       "3   Message unclear. YOLO life savings on AAPL at ...  2021-02-17 05:31:52   \n",
       "4   Leaps on AAPL are pricey.  If you’re going in ...  2021-02-17 05:27:41   \n",
       "..                                                ...                  ...   \n",
       "94  I don’t mean market consensus “undeniable winn...  2023-04-11 13:48:42   \n",
       "95  I had 6680 shares of Waste Management in 2012 ...  2023-04-11 13:17:25   \n",
       "96  Portfolio 1:  \\nCSPX, VXUS  \\nAAPL, ABNB, AZN,...  2023-04-11 12:24:42   \n",
       "97  AAPL. Strong buybacks and good dividend backed...  2023-04-11 11:21:45   \n",
       "98  I'd skip Tesla and split it evenly between MSF...  2023-04-11 06:00:03   \n",
       "\n",
       "         date  \n",
       "0  2021-02-17  \n",
       "1  2021-02-17  \n",
       "2  2021-02-17  \n",
       "3  2021-02-17  \n",
       "4  2021-02-17  \n",
       "..        ...  \n",
       "94 2023-04-11  \n",
       "95 2023-04-11  \n",
       "96 2023-04-11  \n",
       "97 2023-04-11  \n",
       "98 2023-04-11  \n",
       "\n",
       "[9228 rows x 3 columns]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data = pd.concat(dataframes, axis = 0)\n",
    "sentiment_data = sentiment_data[['body', 'utc_datetime_str']]\n",
    "sentiment_data['date'] = [index_str_to_datetime(s) for s in sentiment_data['utc_datetime_str']]\n",
    "sentiment_data['date'] = [convert_to_datetime(str(s)) for s in sentiment_data['date']]\n",
    "\n",
    "sentiment_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stockpredictions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
